{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport collections\nfrom datetime import datetime, timedelta\n\n'''\n\nos.environ[\"XRT_TPU_CONFIG\"] = \"tpu_worker;0;10.0.0.2:8470\"\n\n_VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\nVERSION = \"torch_xla==nightly\"\nCONFIG = {\n    'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n        (datetime.today() - timedelta(1)).strftime('%Y%m%d')))}[VERSION]\n\nDIST_BUCKET = 'gs://tpu-pytorch/wheels'\nTORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\nTORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\nTORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n\n!export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\n!apt-get install libomp5 -y\n!apt-get install libopenblas-dev -y\n\n!pip uninstall -y torch torchvision\n!gsutil cp \"$DIST_BUCKET/$TORCH_WHEEL\" .\n!gsutil cp \"$DIST_BUCKET/$TORCH_XLA_WHEEL\" .\n!gsutil cp \"$DIST_BUCKET/$TORCHVISION_WHEEL\" .\n!pip install \"$TORCH_WHEEL\"\n!pip install \"$TORCH_XLA_WHEEL\"\n!pip install \"$TORCHVISION_WHEEL\"\nimport torch_xla.core.xla_model as xm\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch_lightning","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom torchvision import datasets, transforms, models\nimport os\nimport shutil\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn.functional as F\nimport torch.nn as nn\n#torchvision.utils.save_image\nfrom torchvision import datasets, transforms ,utils\nprint(os.listdir(\"../input\"))\nfrom PIL import Image\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom IPython.display import display, HTML \nfrom matplotlib.pyplot import imshow\nimport numpy as np\nfrom PIL import Image\nimport os\nimport pytorch_lightning as pl\n##!pip install pretrainedmodels\n#import pretrainedmodels\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test_ApKoW4T.csv')\nsample = pd.read_csv('../input/sample_submission_ns2btKE.csv')\ntrain = pd.read_csv('../input/train/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict = {1: 'Cargo', \n2:'Military', \n3:'Carrier', \n4:'Cruise', \n5:'Tankers'}\ntrain['category_label'] = train['category'].map(convertlabeldict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, holdout = train_test_split(train, test_size=0.1, random_state=0, \n                               stratify=train['category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index(drop=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout = holdout.reset_index(drop=True)\nholdout.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainfilenames = train['image'].tolist()\nbasedir = '../input/train/images/'\ndestinationfolder = '../train/'\nfor i,row in train.iterrows():\n    currentfileloc = basedir + row['image']\n    newdirname = destinationfolder + str(row['category'])\n    if not os.path.exists(newdirname):\n        os.makedirs(newdirname)\n    shutil.copy(currentfileloc, newdirname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basedir = '../input/train/images/'\ndestinationfolder = '../holdout/'\nfor i,row in holdout.iterrows():\n    currentfileloc = basedir + row['image']\n    newdirname = destinationfolder + str(row['category'])\n    if not os.path.exists(newdirname):\n        os.makedirs(newdirname)\n    shutil.copy(currentfileloc, newdirname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basedir = '../input/train/images/'\ndestinationfolder = '../test/'\nfor i,row in test.iterrows():\n    currentfileloc = basedir + row['image']\n    #newdirname = destinationfolder\n    if not os.path.exists(destinationfolder):\n        os.makedirs(destinationfolder)\n    shutil.copy(currentfileloc, destinationfolder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_brightness(image):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    rand = random.uniform(0.6, 1.0)\n    hsv[:, :, 2] = rand*hsv[:, :, 2]\n    rand = random.uniform(1.0, 1.5)\n    hsv[:, :, 1] = rand*hsv[:, :, 1]\n    new_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    return new_img\n\n\ndef zoom(image,rows,cols):\n    zoom_pix = random.randint(5, 10)\n    zoom_factor = 1 + (2*zoom_pix)/rows\n    image = cv2.resize(image, None, fx=zoom_factor,\n                       fy=zoom_factor, interpolation=cv2.INTER_LINEAR)\n    top_crop = (image.shape[0] - rows)//2\n    left_crop = (image.shape[1] - cols)//2\n    image = image[top_crop: top_crop+rows,\n                  left_crop: left_crop+cols]\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\ndef createaugimagesv2(dirname,no_of_images):\n    filename = os.listdir(dirname)\n    filename = random.sample(filename, no_of_images)\n    for images in filename:\n        if images[-8:]!='_enh.jpg' and images[-9:]!='_enh1.jpg':\n            imagepath = dirname + images\n            image = cv2.imread(imagepath)\n            rows,cols,channel = image.shape\n            image = np.fliplr(image)\n\n            op1 = random.randint(0, 1)\n            op2 = random.randint(0, 1)\n            op3 = random.randint(0, 1)\n            if op1:\n                image = random_brightness(image)\n            if op2:\n                image = zoom(image,rows,cols)\n            newimagepath = dirname + images.split('.')[0] + '_enh.jpg'\n            try:\n                image = cv2.resize(image, (224, 224))\n                cv2.imwrite(newimagepath, image)\n            except:\n                print(\"file {0} is not converted\".format(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef im_convert(tensor):\n    image = tensor.clone().detach().numpy()\n    image = image.transpose(1, 2, 0)\n    image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n    image = image.clip(0, 1)\n    return image\ndef createaugimages(dirname,no_of_images):\n    filename = os.listdir(dirname)\n    filename = random.sample(filename, no_of_images)\n    for images in filename:\n        if images[-9:]!='_enh1.jpg':\n            imagepath = dirname + images\n            pil_im = Image.open(imagepath, 'r').convert('RGB')\n            op1 = random.randint(0, 1)\n            if op1 ==1:\n                changeimg = transforms.Compose([ \n                                        transforms.RandomRotation(5),\n                                        transforms.Resize(224),\n                                        transforms.ToTensor()\n                                       ])\n            else:\n                changeimg = transforms.Compose([ \n                            transforms.RandomHorizontalFlip(),\n                            transforms.RandomRotation(10),\n                            transforms.Resize(224),\n                            transforms.ToTensor()\n                           ])\n\n            img = changeimg(pil_im)\n            newimagepath = dirname + images.split('.')[0] + '_enh1.jpg'\n            utils.save_image(img,newimagepath)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resizeall(dirname):\n    filename = os.listdir(dirname)\n    non3channel = []\n    for images in filename:\n        imagepath = dirname + images\n        image = cv2.imread(imagepath)\n        if image.shape[2] !=3:\n            non3channel.append(images)\n    return non3channel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict = {1: 'Cargo', \n2:'Military', \n3:'Carrier', \n4:'Cruise', \n5:'Tankers'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 1908 - 1095\nb = 1908 - 1050\nc = 1908 - 824\nd = 1908 - 749","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = '../train/5/'\nno_of_images = a\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../train/2/'\nno_of_images = b\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../train/3/'\nno_of_images = 824\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../train/4/'\nno_of_images = 749\ncreateaugimagesv2(dirname,no_of_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = '../train/1/'\nno_of_images = 500\ncreateaugimages(dirname,no_of_images)\ndirname = '../train/5/'\nno_of_images = 500\ncreateaugimages(dirname,no_of_images)\ndirname = '../train/2/'\nno_of_images = 500\ncreateaugimages(dirname,no_of_images)\ndirname = '../train/3/'\nno_of_images = 824\ncreateaugimages(dirname,no_of_images)\ndirname = '../train/4/'\nno_of_images = 749\ncreateaugimages(dirname,no_of_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = '../train/3/'\nno_of_images = 288\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../train/4/'\nno_of_images = 400\ncreateaugimagesv2(dirname,no_of_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../train\n!ls ../train/1 | wc -l\n!ls ../train/5 | wc -l\n!ls ../train/2 | wc -l\n!ls ../train/4 | wc -l\n!ls ../train/3 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../holdout\n!ls ../holdout/1 | wc -l\n!ls ../holdout/5 | wc -l\n!ls ../holdout/2 | wc -l\n!ls ../holdout/4 | wc -l\n!ls ../holdout/3 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Pl_densenet201(pl.LightningModule):\n\n    def __init__(self,lr=0.001,classes=5):\n        super(Pl_densenet201, self).__init__()\n        self.lr = lr\n        self.classes = classes\n        self.create_densenet201_model()\n\n        \n    def create_densenet201_model(self):\n        self.models = models.densenet201(pretrained=True)\n        self.models.classifier = nn.Sequential(nn.Linear(1920, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, self.classes))\n\n    def forward(self, x):\n        output = self.models(x)\n        return output\n\n    def training_step(self, batch, batch_idx):\n        images, target = batch\n        preds = self.forward(images)\n        loss = F.cross_entropy(preds, target)\n        tensorboard_logs = {'train_loss': loss}\n        return {'loss': loss, 'log': tensorboard_logs}\n    \n    def validation_step(self, batch, batch_idx):\n        images, target = batch\n        preds = self.forward(images)\n        loss = F.cross_entropy(preds, target)\n        return {'val_loss': loss}\n\n    def validation_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        #print(avg_loss)\n        tensorboard_logs = {'val_loss': avg_loss}\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n        \n    def test_step(self, batch, batch_idx):\n        images, target = batch\n        preds = self.forward(images)\n        return {'test_loss': F.cross_entropy(preds, target)}\n\n    def test_end(self, outputs):\n        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n        tensorboard_logs = {'test_loss': avg_loss}\n        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.models.parameters(), lr=self.lr)\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n        return [optimizer], [scheduler]\n\ndef data_transforms(transform_type ='train'):\n    if transform_type=='train':\n        transforms_ret = transforms.Compose([\n                                    transforms.RandomResizedCrop(256,scale=(0.8, 1.0),ratio=(0.75, 1.33)),\n                                    transforms.RandomRotation(degrees=15),\n                                    transforms.CenterCrop(224),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                   ])\n    else:\n        transforms_ret = transforms.Compose([transforms.Resize(256),\n                                transforms.CenterCrop(224), \n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                              ])\n    return transforms_ret\n\ndef prepare_data(train_dir,test_dir,validation_split=0.2):\n    test_dataset = datasets.ImageFolder(test_dir,transform=data_transforms(transform_type='test'))\n    train_dataset = datasets.ImageFolder(train_dir,transform=data_transforms(transform_type='train'))\n    val_len = int(len(train_dataset) * validation_split)\n    train_len = int(len(train_dataset) - val_len)\n    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n    print(len(test_dataset),len(train_dataset),len(val_dataset))\n    return train_dataset,val_dataset,test_dataset\n\ndef create_dataloader(dataset,use_tpu=False,batch_size=64):\n    sampler = None\n    if use_tpu:\n        sampler = torch.utils.data.distributed.DistributedSampler(\n            dataset,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n        )\n\n        loader = torch.utils.data.DataLoader(\n            dataset,\n            sampler=sampler,\n            batch_size=batch_size\n        )\n    else:\n        loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle = True\n        )\n    return loader\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_lightning import Trainer\nfrom argparse import Namespace\ntrain_dir = '/kaggle/train/'\ntest_dir = '/kaggle/holdout/'\n\ntrain_dataset,val_dataset,test_dataset = prepare_data(train_dir,test_dir,validation_split=0.2)\n\ntrain_dataloader = create_dataloader(train_dataset,use_tpu=False,batch_size=64)\nval_dataloader = create_dataloader(val_dataset,use_tpu=False,batch_size=64)\ntest_dataloader = create_dataloader(test_dataset,use_tpu=False,batch_size=64)\n\nmodel = Pl_densenet201(lr=0.001,classes=5)\n\n# most basic trainer, uses good defaults\n#trainer = Trainer(num_tpu_cores=8, precision=16,max_epochs=2)\ntrainer = Trainer(gpus=1, max_epochs=22)\n#trainer = Trainer()\n#trainer = Trainer(num_tpu_cores=8, max_epochs=2, precision=16)\ntrainer.fit(model,train_dataloader,val_dataloader,test_dataloader) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, test_image_name,transform,image_size,modeltype='other'):\n    test_image = Image.open(test_image_name).convert('RGB')\n    test_image_tensor = transform(test_image)\n    if torch.cuda.is_available():\n        test_image_tensor = test_image_tensor.view(1, 3, image_size, image_size).cuda()\n    else:\n        test_image_tensor = test_image_tensor.view(1, 3, image_size, image_size)\n    with torch.no_grad():\n        model.eval()\n        if modeltype == 'inception':\n            out = model(test_image_tensor)[0]\n        else:\n            out = model(test_image_tensor)\n        ps = torch.exp(out)\n    return test_image_name,ps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extractfilename(val):\n    return os.path.split(val)[1]\n\ndef maxtensorval(val):\n    #ps = torch.exp(val)\n    #ps = F.softmax(val,dim=1)\n    top_p, top_class = val.topk(1)\n    return top_class+1\n\nimage_size = 224 \ntest_transforms = transforms.Compose([transforms.Resize(256),\n                                    transforms.CenterCrop(image_size), \n                                  transforms.ToTensor(),\n#                                  transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                              ])\nbasedir = '../test/'\nprediction_df = pd.DataFrame(columns=['image', 'category'])\nmodelname = 'other'\nprint(\"Prediction of model {0} started\".format(modelname))\nfor i,row in test.iterrows():\n    pathfile = basedir + row['image']\n    test_image_name,imagetype = predict(model, pathfile,test_transforms,image_size,modeltype=modelname)\n    prediction_df.loc[i] = [test_image_name,imagetype]\nprint(\"Prediction for model {0} completed\".format(modelname))\nprediction_df['image']  = prediction_df['image'].apply(extractfilename)\nprediction_df['category'] = prediction_df['category'].apply(maxtensorval)\nprediction_df['category'] = prediction_df['category'].apply(int)\nprediction_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_df['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_df.to_csv('prediction.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}